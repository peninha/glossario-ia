# Aprendizado por Reforço com Feedback Humano

**Reinforcement Learning from Human Feedback** · *RLHF*

Método de alinhar [modelos](../conceitos-fundamentais/modelo.md) generativos às preferências humanas, usando reforço baseado em feedback de avaliadores.


**Tags:** [`reinforcement-learning`](../tags.md#reinforcement-learning) · [`safety`](../tags.md#safety)

---

[:material-arrow-left: Voltar para IA Generativa](index.md){ .md-button }
[📝 Editar este termo](https://github.com/seu-usuario/glossario-ia/edit/main/glossario.yaml){ .md-button .md-button--primary }
