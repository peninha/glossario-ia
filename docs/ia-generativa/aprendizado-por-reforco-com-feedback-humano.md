# Aprendizado por ReforÃ§o com Feedback Humano

**Reinforcement Learning from Human Feedback** Â· *RLHF*

MÃ©todo de alinhar [modelos](../conceitos-fundamentais/modelo.md) generativos Ã s preferÃªncias humanas, usando reforÃ§o baseado em feedback de avaliadores.


**Tags:** `rlhf` Â· `alinhamento` Â· `feedback-humano`

---

[:material-arrow-left: Voltar para IA Generativa](index.md){ .md-button }
[ğŸ“ Editar este termo](https://github.com/seu-usuario/glossario-ia/edit/main/glossario.yaml){ .md-button .md-button--primary }
