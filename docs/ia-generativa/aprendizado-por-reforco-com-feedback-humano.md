# Aprendizado por ReforÃ§o com Feedback Humano

**Reinforcement Learning from Human Feedback** Â· *RLHF*

MÃ©todo de alinhar [modelos](../conceitos-fundamentais/modelo.md) generativos Ã s preferÃªncias humanas, usando reforÃ§o baseado em feedback de avaliadores.


**Tags:** [`reinforcement-learning`](../tags.md#reinforcement-learning) Â· [`safety`](../tags.md#safety)

---

[:material-arrow-left: Voltar para IA Generativa](index.md){ .md-button }
[ğŸ“ Editar este termo](https://github.com/seu-usuario/glossario-ia/edit/main/glossario.yaml){ .md-button .md-button--primary }
