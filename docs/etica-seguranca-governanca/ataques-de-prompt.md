# Ataques de Prompt

**Prompt Injection**

TÃ©cnicas que induzem o [modelo](../conceitos-fundamentais/modelo.md) a ignorar instruÃ§Ãµes/limites e gerar saÃ­das indesejadas.


**Tags:** `ataques` Â· `seguranca` Â· `manipulacao`

---

[:material-arrow-left: Voltar para Ã‰tica, SeguranÃ§a e GovernanÃ§a](index.md){ .md-button }
[ğŸ“ Editar este termo](https://github.com/seu-usuario/glossario-ia/edit/main/glossario.yaml){ .md-button .md-button--primary }
