# Conceitos Éticos, de Segurança e de Governança

Princípios, práticas e regulamentações para uso responsável de IA

## Termos nesta categoria

<div class="grid cards" markdown>

- **[Alinhamento em IA](alinhamento-em-ia.md)**

    *AI Alignment*

    Área de pesquisa que busca garantir que sistemas de IA, mesmo aqueles super inteligentes, ajam de forma alinhada aos valores e [objetivos](../agentes-ia/objetivo.md) humanos.

- **[Anonimização](anonimizacao.md)**

    *Anonymization*

    Processo de remover ou alterar informações identificáveis de [dados](../conceitos-fundamentais/dados.md) para proteger a identidade dos indivíduos, garantindo a privacidade em tráfego, análises e armazenamento.

- **[Aprendizado Federado](aprendizado-federado.md)**

    *Federated Learning*

    [Treinamento](../conceitos-fundamentais/treinamento.md) de IA descentralizado para preservar a privacidade dos [dados](../conceitos-fundamentais/dados.md) (ver [anonimização](../etica-seguranca-governanca/anonimizacao.md)).

- **[Ataques de Prompt](ataques-de-prompt.md)**

    *Prompt Injection*

    Técnicas que induzem o [modelo](../conceitos-fundamentais/modelo.md) a ignorar instruções/limites e gerar saídas indesejadas.

- **[Conformidade](conformidade.md)**

    *Compliance*

    Adequação de sistemas de IA a marcos regulatórios, normas técnicas e políticas internas. Inclui avaliações de risco/impacto, classificações por nível de risco e requisitos de documentação.

- **[Deriva de Dados](deriva-de-dados.md)**

    *Data Drift*

    Mudanças na distribuição dos [dados](../conceitos-fundamentais/dados.md) de entrada ao longo do tempo que podem degradar o desempenho do [modelo](../conceitos-fundamentais/modelo.md). Exige [monitoramento contínuo](../etica-seguranca-governanca/monitoramento-continuo.md) e estratégias de adaptação.

- **[Deriva de Modelo](deriva-de-modelo.md)**

    *Model Drift*

    Degradação do desempenho do [modelo](../conceitos-fundamentais/modelo.md) devido a mudanças no [ambiente](../agentes-ia/ambiente.md) ou nos [dados](../conceitos-fundamentais/dados.md). Requer [treinamento](../conceitos-fundamentais/treinamento.md) periódico para manutenção da qualidade.

- **[Exemplos Adversariais](exemplos-adversariais.md)**

    *Adversarial Examples*

    Perturbações sutis em entradas (texto/imagem/áudio) que levam o [modelo](../conceitos-fundamentais/modelo.md) ao erro. Defesas: *adversarial training*, regularização e detecção de anomalias.

- **[Explicabilidade](explicabilidade.md)**

    *Explainability* · `XAI`

    Capacidade de um [modelo](../conceitos-fundamentais/modelo.md) em explicar, de maneira confiável, como chegou a uma determinada decisão.

- **[Gestão de Incidentes](gestao-de-incidentes.md)**

    *Incident Management*

    Processos estruturados para identificar, responder e resolver problemas em sistemas de IA, incluindo protocolos de escalação, comunicação e recuperação.

- **[Guard Rails](guard-rails.md)**

    *Guardrails*

    Conjuntos de restrições e limites implementados em sistemas de IA para possibilitar operações seguras e éticas.

- **[Guidelines](guidelines.md)**

    *Guidelines*

    Diretrizes que orientam o desenvolvimento e uso responsável de sistemas de IA.

- **[IA Ética](ia-etica.md)**

    *Ethical AI*

    O mesmo que [IA Responsável](../etica-seguranca-governanca/ia-responsavel.md), mas com um foco maior na ética.

- **[IA Responsável](ia-responsavel.md)**

    *Responsible AI*

    Conjunto de princípios e práticas para projetar, treinar, avaliar e operar sistemas de IA de forma segura, ética e justa.

- **[Interpretabilidade](interpretabilidade.md)**

    *Interpretability*

    Área de pesquisa que busca compreender os mecanismos internos de um [modelo](../conceitos-fundamentais/modelo.md) que geram uma determinada saída ou decisão.

- **[Jailbreak](jailbreak.md)**

    *Jailbreak*

    Técnica que induz o [modelo](../conceitos-fundamentais/modelo.md) a ignorar restrições e agir livremente, possivelmente de maneira maliciosa ou insegura.

- **[Marcação de Conteúdo Sintético](marcacao-de-conteudo-sintetico.md)**

    *Synthetic Content Marking*

    Técnicas para indicar que um conteúdo foi gerado por IA (ex.: marcas d'água, assinaturas criptográficas, padrões de proveniência). Auxiliam no combate a *deepfakes* e desinformação.

- **[Moderação de Conteúdo](moderacao-de-conteudo.md)**

    *Content Moderation*

    Sistemas e processos para identificar, filtrar e remover conteúdo inadequado, nocivo ou que violam políticas de uso.

- **[Monitoramento Contínuo](monitoramento-continuo.md)**

    *Continuous Monitoring*

    Acompanhamento sistemático do desempenho e comportamento dos sistemas de IA em produção, incluindo métricas, alertas e detecção de anomalias.

- **[Observabilidade de IA](observabilidade-de-ia.md)**

    *AI Observability*

    Monitoramento em tempo real sobre o comportamento de sistemas de IA, facilitando a detecção de anomalias.

- **[Regulação de IA](regulacao-de-ia.md)**

    *AI Regulation*

    Marco legal e normativo que estabelece regras para o desenvolvimento, uso e comercialização de sistemas de IA. Define responsabilidades, limites e requisitos de segurança para diferentes aplicações.

- **[Responsabilização Algorítmica](responsabilizacao-algoritmica.md)**

    *Algorithmic Accountability*

    Responsabilidade pelos impactos das decisões automatizadas.

- **[Robustez](robustez.md)**

    *Robustness*

    Capacidade de um sistema de IA de manter desempenho confiável mesmo em condições adversas ou com [dados](../conceitos-fundamentais/dados.md) inesperados. Inclui resistência a falhas, ruído e variações nos dados de entrada.

- **[Segurança de IA](seguranca-de-ia-safety.md)**

    *AI Safety*

    Área focada em garantir que sistemas de IA funcionem de forma segura e alinhada aos valores humanos. Aborda riscos como [alinhamento](../etica-seguranca-governanca/alinhamento-em-ia.md) incorreto, comportamento inesperado e capacidades emergentes que podem representar ameaças à humanidade.

- **[Segurança de IA](seguranca-de-ia-security.md)**

    *AI Security*

    Proteção de sistemas de IA contra ataques, vazamentos de [dados](../conceitos-fundamentais/dados.md) e uso malicioso. Inclui resistência a [ataques de prompt](../etica-seguranca-governanca/ataques-de-prompt.md), defesa contra [exemplos adversariais](../etica-seguranca-governanca/exemplos-adversariais.md) e prevenção de [jailbreaks](../etica-seguranca-governanca/jailbreak.md).

- **[Viés e Equidade](vies-e-equidade.md)**

    *Bias and Fairness*

    Identificação e mitigação de preconceitos nos [modelos](../conceitos-fundamentais/modelo.md) de IA.

</div>

**Total de termos:** 26

