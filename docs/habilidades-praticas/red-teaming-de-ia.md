# Red Teaming de IA

**AI Red Teaming**

Testes ofensivos controlados para descobrir falhas, vieses e caminhos de abuso ([ataques de prompt](../etica-seguranca-governanca/ataques-de-prompt.md), [jailbreak](../etica-seguranca-governanca/jailbreak.md), fuga de [dados](../conceitos-fundamentais/dados.md)), com planos de correÃ§Ã£o.


**Tags:** `testes` Â· `falhas` Â· `abuso`

---

[:material-arrow-left: Voltar para Habilidades e PrÃ¡ticas](index.md){ .md-button }
[ğŸ“ Editar este termo](https://github.com/seu-usuario/glossario-ia/edit/main/glossario.yaml){ .md-button .md-button--primary }
